{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxNQr1lMP78SItt7/vdBtl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/majidsadrii/persian_vehicle_license/blob/main/plates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnfScpj_7uE3",
        "outputId": "125a3f22-b28a-46fe-86ea-41742ceb5599"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "project_dir =  '/content/drive/MyDrive/car_plate' \n",
        "images_n_vids_path = \"/content/dataset/Vehicle Plates/Vehicle Plates\"\n",
        "savepath = \"/content/drive\" \n",
        "weights = '/content/drive/MyDrive/car_plate/yolov7/runs/train/exp6/weights/best.pt'\n",
        "\n",
        "image_size = 640\n",
        "\n",
        "os.chdir(project_dir)\n",
        "!pip install -r requirements.txt\n",
        "from colorama import Fore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMkQDFb28QPs",
        "outputId": "495e9646-9709-4bd3-be37-da2b332dc850"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deep-sort-realtime\n",
            "  Downloading deep_sort_realtime-1.3.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting easyocr\n",
            "  Downloading easyocr-1.6.2-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.9/dist-packages (from deep-sort-realtime->-r requirements.txt (line 1)) (4.6.0.66)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from deep-sort-realtime->-r requirements.txt (line 1)) (1.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from deep-sort-realtime->-r requirements.txt (line 1)) (1.22.4)\n",
            "Collecting opencv-python-headless<=4.5.4.60\n",
            "  Downloading opencv_python_headless-4.5.4.60-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyclipper\n",
            "  Downloading pyclipper-1.3.0.post4-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (608 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m608.2/608.2 KB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.9/dist-packages (from easyocr->-r requirements.txt (line 2)) (0.19.3)\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 KB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from easyocr->-r requirements.txt (line 2)) (1.13.1+cu116)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from easyocr->-r requirements.txt (line 2)) (8.4.0)\n",
            "Collecting python-bidi\n",
            "  Downloading python_bidi-0.4.2-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from easyocr->-r requirements.txt (line 2)) (6.0)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.9/dist-packages (from easyocr->-r requirements.txt (line 2)) (0.14.1+cu116)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.9/dist-packages (from easyocr->-r requirements.txt (line 2)) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.5->easyocr->-r requirements.txt (line 2)) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.5->easyocr->-r requirements.txt (line 2)) (2.25.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from python-bidi->easyocr->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image->easyocr->-r requirements.txt (line 2)) (2023.2.28)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image->easyocr->-r requirements.txt (line 2)) (23.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->easyocr->-r requirements.txt (line 2)) (2.9.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image->easyocr->-r requirements.txt (line 2)) (3.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->easyocr->-r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5->easyocr->-r requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5->easyocr->-r requirements.txt (line 2)) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5->easyocr->-r requirements.txt (line 2)) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5->easyocr->-r requirements.txt (line 2)) (2022.12.7)\n",
            "Installing collected packages: pyclipper, ninja, python-bidi, opencv-python-headless, colorama, deep-sort-realtime, easyocr\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.7.0.72\n",
            "    Uninstalling opencv-python-headless-4.7.0.72:\n",
            "      Successfully uninstalled opencv-python-headless-4.7.0.72\n",
            "Successfully installed colorama-0.4.6 deep-sort-realtime-1.3.2 easyocr-1.6.2 ninja-1.11.1 opencv-python-headless-4.5.4.60 pyclipper-1.3.0.post4 python-bidi-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# persian font "
      ],
      "metadata": {
        "id": "L0_k5IQTKwPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if  not os.path.isfile('/content/drive/MyDrive/car_plate/persian_font/Vazirmatn-Black.ttf'):\n",
        "  print(Fore.CYAN,'donwloading appropriate persian font')\n",
        "  os.chdir('/content')\n",
        "  !git clone https://github.com/rastikerdar/vazirmatn.git\n",
        "  %cp /content/vazirmatn/fonts/ttf/* /content/drive/MyDrive/car_plate/persian_font\n",
        "else:\n",
        "    print(Fore.CYAN,'you have already vaziri font')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqnJiK1uKsxv",
        "outputId": "8aeae6a2-1c65-43af-ec68-c2d02f15abae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m you have already vaziri font\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yolo_path = os.path.join(project_dir, \"yolov7\")\n",
        "os.chdir(yolo_path)\n",
        "import shutil\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from typing import Union\n",
        "import torch\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "from models.experimental import attempt_load\n",
        "from utils.general import check_img_size\n",
        "from utils.torch_utils import select_device, TracedModel\n",
        "from utils.datasets import letterbox\n",
        "from utils.general import non_max_suppression, scale_coords\n",
        "# from utils.plots import plot_one_box, plot_one_box_PIL\n",
        "from copy import deepcopy\n",
        "import easyocr\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "iwSL399G4amR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "trace = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jn66vCCsBxmX",
        "outputId": "c8a5293f-ced2-43e0-fa37-e98cc7ebb6e3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "half = device.type != 'cpu'  # half precision only supported on CUDA\n",
        "\n",
        "# Load model\n",
        "model = attempt_load(weights, map_location=device)  # load FP32 model\n",
        "stride = int(model.stride.max())  # model stride\n",
        "imgsz = check_img_size(image_size, s=stride)  # check img_size\n",
        "\n",
        "if trace:\n",
        "    model = TracedModel(model, device, image_size)\n",
        "\n",
        "if half:\n",
        "    model.half()  # to FP16\n",
        "    \n",
        "if device.type != 'cpu':\n",
        "    model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once\n",
        "\n",
        "\n",
        "# Load OCR\n",
        "reader = easyocr.Reader(['fa'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ6zksrP4b9H",
        "outputId": "79452fd5-67ce-4927-d0ae-766a27825a69"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageDraw, ImageFont\n",
        "def plot_one_box_PIL(box, img, color=None, label=None, line_thickness=None,font_path=None):\n",
        "    img = Image.fromarray(img)\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    line_thickness = line_thickness or max(int(min(img.size) / 200), 2)\n",
        "    draw.rectangle(box, width=line_thickness, outline=tuple(color))  # plot\n",
        "    if label:\n",
        "        fontsize = max(round(max(img.size) / 40), 12)\n",
        "        font = ImageFont.truetype(font_path, fontsize)\n",
        "        txt_width, txt_height = font.getsize(label)\n",
        "        draw.rectangle([box[0], box[1] - txt_height + 4, box[0] + txt_width, box[1]], fill=tuple(color))\n",
        "        draw.text((box[0], box[1] - txt_height + 1), label, fill=(255, 255, 255), font=font)\n",
        "    return np.asarray(img)\n"
      ],
      "metadata": {
        "id": "5hMGk4jWI39u"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt, atan, degrees\n",
        "   \n",
        "def find_longest_line(plate_img_gr):\n",
        "    kernel_size = 3\n",
        "    blur_gray = cv.GaussianBlur(plate_img_gr, (kernel_size, kernel_size), 0)\n",
        "\n",
        "    low_threshold = 150\n",
        "    high_threshold = 200\n",
        "\n",
        "    edges = cv.Canny(blur_gray, low_threshold, high_threshold)\n",
        "\n",
        "    rho = 1  # distance resolution in pixels of the Hough grid\n",
        "    theta = np.pi / 180  # angular resolution in radians of the Hough grid\n",
        "    threshold = 15  # minimum number of votes (intersections in Hough grid cell)\n",
        "    min_line_length = 50  # minimum number of pixels making up a line\n",
        "    max_line_gap = 5  # maximum gap in pixels between connectable line segments\n",
        "    line_image = np.copy(plate_img_gr) * 0  # creating a blank to draw lines on\n",
        "\n",
        "    # Run Hough on edge detected image\n",
        "    # Output \"lines\" is an array containing endpoints of detected line segments\n",
        "    lines = cv.HoughLinesP(edges, rho, theta, threshold, np.array([]),\n",
        "                        min_line_length, max_line_gap)\n",
        "\n",
        "    lls = []\n",
        "    if  lines is not None:\n",
        "      for indx, line in enumerate(lines):\n",
        "          for x1,y1,x2,y2 in line:\n",
        "              cv.line(line_image,(x1,y1),(x2,y2),(255,0,0),5)\n",
        "              line_length = sqrt((x2-x1)**2 + (y2-y1)**2)\n",
        "              lls.append((indx,line_length))\n",
        "      lls.sort(key = lambda x: x[1])\n",
        "      linessorted = []\n",
        "      for (indx,ll) in lls:\n",
        "          linessorted.append(lines[indx])\n",
        "      return linessorted\n",
        "    else:\n",
        "      return False\n",
        "\n",
        "def find_line_angle(line):\n",
        "    x1,y1,x2,y2 = line[0]\n",
        "    angle = degrees(atan(((y2-y1)/(x2-x1))))\n",
        "    return angle\n",
        "\n",
        "def rotate_image(plate_img_gr, angle):\n",
        "    (h, w) = plate_img_gr.shape\n",
        "    (cX, cY) = (w // 2, h // 2)\n",
        "    M = cv.getRotationMatrix2D((cX, cY), angle, 1.0)\n",
        "    rotated = cv.warpAffine(plate_img_gr, M, (w, h))\n",
        "    return rotated\n",
        "\n",
        "def adjust_cropping(rotated_img):\n",
        "    h,w = rotated_img.shape\n",
        "    targ_h = int(w/4)\n",
        "    crop_h = int((h - targ_h)/2)\n",
        "    cropped_rotated_img = rotated_img[crop_h:h-crop_h,:]\n",
        "    return cropped_rotated_img\n",
        "\n",
        "def make_plate_horizantal(plate_img,save_rotated =False,save_path=None,save_name=None):\n",
        "  plate_img_gr = cv.cvtColor(plate_img, cv.COLOR_BGR2GRAY)\n",
        "  linessorted = find_longest_line(plate_img_gr)\n",
        "  if linessorted:\n",
        "\n",
        "    rot_angle = find_line_angle(linessorted[-1])\n",
        "    rotated_img = rotate_image(plate_img_gr, rot_angle)\n",
        "    cropped_rotated_img = adjust_cropping(rotated_img)\n",
        "    if save_rotated:\n",
        "      cv.imwrite(os.path.join(save_path, 'plate_{}.jpg'.format(save_name)), plate_img_gr)\n",
        "      cv.imwrite(os.path.join(save_path, 'plate_{}_rotated.jpg'.format(save_name)), cropped_rotated_img)\n",
        "    return(cropped_rotated_img,rot_angle)\n",
        "\n",
        "  else:\n",
        "    print(Fore.RED,'Image has not been rotated',Fore.BLACK)\n",
        "    return None ,None\n",
        "      \n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "QEYszZVC7ikE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_plate(source_image,img_size = 640):\n",
        "  \n",
        "    stride = 32\n",
        "    img = letterbox(source_image, img_size, stride=stride)[0]\n",
        "\n",
        "    # Convert\n",
        "    img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\n",
        "    img = np.ascontiguousarray(img)\n",
        "    img = torch.from_numpy(img).to(device)\n",
        "    img = img.half() if half else img.float()  # uint8 to fp16/32\n",
        "    img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
        "    if img.ndimension() == 3:\n",
        "        img = img.unsqueeze(0)\n",
        "        \n",
        "    with torch.no_grad():\n",
        "        # Inference\n",
        "        pred = model(img, augment=True)[0]\n",
        "\n",
        "    # Apply NMS\n",
        "    pred = non_max_suppression(pred, 0.25, 0.45, classes=0, agnostic=True)\n",
        "\n",
        "    plate_detections = []\n",
        "    det_confidences = []\n",
        "    \n",
        "    # Process detections\n",
        "    for i, det in enumerate(pred):  # detections per image\n",
        "        if len(det):\n",
        "            # Rescale boxes from img_size to im0 size\n",
        "            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], source_image.shape).round()\n",
        "\n",
        "            # Return results\n",
        "            for *xyxy, conf, cls in reversed(det):\n",
        "                coords = [int(position) for position in (torch.tensor(xyxy).view(1, 4)).tolist()[0]]\n",
        "                plate_detections.append(coords)\n",
        "                det_confidences.append(conf.item())\n",
        "\n",
        "    return plate_detections, det_confidences\n",
        "\n",
        "\n",
        "\n",
        "    return True\n",
        "def ocr_plate(plate_region):\n",
        "    # Image pre-processing for more accurate OCR\n",
        "    # cv.imwrite(os.path.join(savepath, \"plate_img.png\"), plate_region)\n",
        "    rescaled = cv.resize(plate_region, None, fx=1.2, fy=1.2, interpolation=cv.INTER_CUBIC)\n",
        "    if  len( rescaled .shape) > 2:\n",
        "         grayscale = cv.cvtColor(rescaled, cv.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "      grayscale =rescaled\n",
        "    \n",
        "          \n",
        "    # OCR the preprocessed image\n",
        "    grayscale_blur = cv.medianBlur(grayscale, 1)\n",
        "    ret, thresh1 = cv.threshold(grayscale_blur, 120, 255, cv.THRESH_BINARY + cv.THRESH_OTSU) \n",
        "    cv.imwrite(os.path.join(savepath, \"grayscale_blur.png\"), grayscale_blur)\n",
        "    plate_text_easyocr = reader.readtext(grayscale_blur)\n",
        "    if plate_text_easyocr:\n",
        "        (bbox, text_easyocr, ocr_confidence) = plate_text_easyocr[0]\n",
        "        print(\"plate_text Easyocr \", text_easyocr)\n",
        "    else:\n",
        "        text_easyocr = \"_\"\n",
        "        ocr_confidence = 0\n",
        "    #if ocr_confidence == 'nan':\n",
        "    \n",
        "    return text_easyocr, ocr_confidence\n",
        "\n",
        "\n",
        "def crop(image, coord):\n",
        "    cropped_image = image[int(coord[1]):int(coord[3]), int(coord[0]):int(coord[2])]\n",
        "    return cropped_image\n",
        "def get_plates_from_image(input,save_dir,Save_Name=None,font_location=None):\n",
        "    if input is None:\n",
        "        return None\n",
        "    plate_detections, det_confidences = detect_plate(input)\n",
        "    plate_texts = []\n",
        "    ocr_confidences = []\n",
        "    detected_image = deepcopy(input)\n",
        "    for coords in plate_detections:\n",
        "        plate_region = crop(input, coords)\n",
        "        plate_region_rotated,rot_ang = make_plate_horizantal(plate_region,save_rotated =True,save_path=save_dir,save_name=Save_Name)\n",
        "        if plate_region_rotated is not None:\n",
        "          plate_text, ocr_confidence = ocr_plate(plate_region_rotated)\n",
        "        else:\n",
        "          plate_text, ocr_confidence = ocr_plate(plate_region)\n",
        "        plate_texts.append(plate_text)\n",
        "        ocr_confidences.append(ocr_confidence)\n",
        "        detected_image = plot_one_box_PIL(coords, detected_image, label=plate_text, color=[0, 150, 255], line_thickness=2,font_path=font_location)\n",
        "        cv.imwrite(os.path.join(save_dir, 'detected_{}.jpg'.format(Save_Name)),detected_image)\n",
        "    return detected_image\n",
        "\n"
      ],
      "metadata": {
        "id": "1bmJv4sUFQrj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/car_plate/samples'\n",
        "save_dir = '/content'\n",
        "persian_font ='/content/drive/MyDrive/car_plate/persian_font/Vazirmatn-Regular.ttf'\n",
        "ALL_img = os.listdir( data_dir)\n",
        "images_to_process = []\n",
        "images_names = []\n",
        "for i in range(len(ALL_img)):\n",
        "  tem = ALL_img[i].split('.')\n",
        "  \n",
        "  if tem[-1] == 'jpg' or tem[-1] =='png':\n",
        "    images_names.append(tem[0].split('/')[-1])\n",
        "    images_to_process.append(data_dir +'/'+ALL_img[i])\n",
        "if len(images_to_process)  ==0:\n",
        "  print(Fore.RED,'there is no jpg or png image')\n",
        "\n",
        "for index in range(len(images_to_process )):\n",
        "  input_img = images_to_process[index]\n",
        "  plate_image = cv.imread(input_img)\n",
        "  result = get_plates_from_image(plate_image,save_dir= save_dir ,Save_Name = images_names[index],font_location=persian_font )\n"
      ],
      "metadata": {
        "id": "au65VsF0pTNC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f254e71-95c4-4691-9821-58782cefd088"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "plate_text Easyocr  مابران\n",
            "plate_text Easyocr  ابدان\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8WqgBT-heX0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iCYvEL45eXzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xnfn3-X3c0XQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}